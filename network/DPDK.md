# 3.4.1 数据平面开发套件 DPDK

2010 年，Intel 主导开发了 DPDK（Data Plane Development Kit，数据平面开发套件），基于“内核旁路”理念构建高性能网络应用方案，并逐步发展为一套成熟的技术体系。

最初，DPDK 是 Intel 为推销自家硬件而开发的高性能网络驱动组件，专门针对 Intel 处理器和网卡。随着 DPDK 开源，越来越多厂商开始贡献代码，DPDK 扩展了对更多硬件的支持：不仅支持 Intel 处理器，还兼容 AMD、ARM 等厂商的处理器；网卡支持范围也涵盖了 Intel、Mellanox、ARM 集成网卡等。因此，DPDK 也逐渐具有广泛的适用性。

图 3-6 展示了 DPDK（Fast Path）与传统内核网络（Slow Path）之间的区别。在 Linux 系统中，DPDK 的库和应用程序在用户空间的编译、链接和加载方式与普通程序相同，但它们的数据包传输路径却大相径庭：

- **传统内核网络**（图左侧）：网络数据包从网络接口卡（NIC）出发，经驱动程序、内核协议栈处理，最终通过 Socket 接口传递给用户空间的业务层。
- **DPDK 加速网络**（图右侧）：在该方案中，网络数据包通过用户空间 I/O（UIO）技术，直接绕过内核协议栈，从网卡传输至 DPDK 基础库，再传递至业务逻辑。也就是说，DPDK 绕过了 Linux 内核协议栈的数据包处理过程，在用户空间直接进行收发和处理。

:::center
  ![](../assets/dpdk.png)<br/>
 图 3-6 DPDK 与传统内核网络对比
:::

爱奇艺开源的 DPVS 是 DPDK 技术在负载均衡领域的成功应用。图 3-7 展示了 DPVS 与标准 LVS 的性能对比。从每秒转发数据包数量（Packet Per Second，PPS）的指标来看，DPVS 的性能表现比 LVS 高出 300%。

:::center
  ![](../assets/dpvs-performance.png)<br/>
 图 3-7 DPVS 与 LVS 的 PPS 性能指标对比（结果越高，性能越好）[图片来源](https://github.com/iqiyi/dpvs)
:::

对于海量用户规模的互联网应用，通常需要部署数千甚至数万台服务器。如果能将单机性能提升十倍甚至百倍，无论从硬件投入还是运营成本角度，都能实现显著的成本节约。这种技术变革带来的潜在效益，毫无疑问非常诱人。

DPDK 是由硬件厂商主导的“内核旁路”技术。在下一节，笔者将介绍由社区开发者主导的另一类“内核旁路”技术。