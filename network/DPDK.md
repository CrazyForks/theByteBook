# 3.4.1 数据平面开发套件 DPDK

2010 年，由 Intel 领导的 DPDK（Data Plane Development Kit，数据平面开发套件）实现了一套基于“内核旁路”思想的高性能网络应用开发解决方案，并逐渐成为了独树一帜的成熟技术体系。

不同于 Linux 系统以通用性设计为目的，DPDK 为 Intel 处理器架构提供了库函数和驱动的支持，专注于网络应用中数据包的高性能处理。**也就是说 DPDK 绕过了 Linux 内核协议栈对数据包的处理过程，在用户空间直接对数据包进行收发与处理**。图 3-17 对比展示了 DPDK 与传统内核网络。在 Linux 系统中，位于用户空间的 DPDK Lib 和 APP 被视为一个普通的用户进程，其编译、连接和加载方式和普通程序没什么区别。但两者网络数据包在 Linux 系统中的传输路径完全不同：

- 左侧展示的是传统内核方式：网络数据包自网络接口卡（NIC）出发，经过驱动程序，内核协议栈，最后通过 Socket 接口传递至业务逻辑。
- 右侧则展示的是 DPDK 方式：在该方案中，网络数据包利用用户空间 I/O（UIO）技术，直接绕过内核协议栈，从网卡转移到 DPDK 基础库，然后传递至业务逻辑。

:::center
  ![](../assets/dpdk.png)<br/>
 图 3-17 DPDK 与传统内核网络对比
:::

目前，网络密集型系统如负载均衡、金融量化交易和分布式机器学习等，已经广泛利用 DPDK 技术跳过内核，在用户态直接处理数据包，从而充分发挥硬件资源，实现单机千万级并发连接，同时业务网络延迟缩短到微秒级别。

图 3-18 展示了基于 DPDK 的高性能四层负载均衡 DPVS 与基于 Linux 内核网络的 LVS 四层负载均衡性能对比。从每秒转发数据包数量（PPS）这一指标来看，DPVS 的表现比 LVS 高出 300%。对于海量用户规模的互联网应用来说，动辄需要部署数千、甚至数万台服务器，如果能将单机性能提升十倍甚至百倍，无论是从硬件投入还是运营成本上来看都能带来非常可观的成本削减，这样的技术变革带来的潜在效益非常诱人。

:::center
  ![](../assets/dpvs-performance.png)<br/>
 图 3-18 DPVS 与 LVS 的 PPS 性能指标对比 [图片来源](https://github.com/iqiyi/dpvs)
:::


